{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "step_2-database-to-csv.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oetKDuRLX6g",
        "colab_type": "text"
      },
      "source": [
        "**This jupyter notebook that demonstrates how to:**\n",
        "\n",
        "1. Connect to Oracle database;\n",
        "2. Run a query limiting sizes of results;\n",
        "3. Create a csv file with results at google drive.\n",
        "\n",
        "The CSV files creation process was necessary to make possible analysis and model tests without a database setup process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjoF5XmbiRXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#install 2 libs that are not found at google colab by default\n",
        "!pip install google\n",
        "!pip install cx_Oracle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwxmAcrVIkTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "from IPython.display import display,clear_output\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import cx_Oracle\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "#parameters to connect to Oracle database (there is a Docker file at the repo \n",
        "#to create a database instance)\n",
        "ip = 'database'\n",
        "port = 1521\n",
        "SID = 'sid'\n",
        "user = 'user'\n",
        "password = 'password'\n",
        "\n",
        "dsn_tns = cx_Oracle.makedsn(ip, port, SID)\n",
        "#encoding and access parameters depends on database installation\n",
        "connection = cx_Oracle.connect(user, \n",
        "                               password, \n",
        "                               dsn_tns, \n",
        "                               encoding = \"UTF-8\", \n",
        "                               nencoding = \"UTF-8\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKZSgJ_j8wog",
        "colab_type": "text"
      },
      "source": [
        "**Mount google drive to access files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OwMW61e8uNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HeJZGWRYy0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubQTVXJzY94e",
        "colab_type": "text"
      },
      "source": [
        "**Information about the database**\n",
        "\n",
        "\n",
        "*   Alarm table (SYSTEM.ALARMS): where alarms and events are logged. The most important columns are:\n",
        "  * INTIME: datetime when event/alarm started;\n",
        "  * OUTTIME: datetime when event/alarm ended;\n",
        "  * MESSAGE: datetime description or message related to the alarm/event;\n",
        "  * TAG: datetime device or localization related to the alarm/event;\n",
        "  * AREA: lift station related to the alarm/event.\n",
        "*   History tables: where timeseries are saved. In addition to the timestamp column, process data is found. The storage interval varies from one type of history to another.\n",
        "\n",
        "**Some of the table and columns names were changed for security reasons**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk29uRf6IkTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Important defines:\n",
        "#total number of lift stations\n",
        "NUMBER_OF_LIFT_STATIONS = 30 \n",
        "\n",
        "#number of pumps per lift stations\n",
        "PUMPS_PER_LIFT_STATION  = [2,2,3,3,3,1,2,3,2,2,3,3,2,2,2,\n",
        "                           2,3,2,2,2,2,2,2,2,2,2,2,2,2,2]\n",
        "\n",
        "#google drive folder where datasets are stored\n",
        "DATASETS_DIR = r'/content/gdrive/My Drive/datasets/'                         \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cVp29iEKG61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_csvfile_from_query(\n",
        "    connection, query_format, filename_format, lif_station_index, pump_index): \n",
        "    \"\"\"function to create csv file using query results:\n",
        "\n",
        "    Args:\n",
        "        connection (): connection to database.\n",
        "        query_format (str): string format to query.\n",
        "        filename_format (str): string format to filename.\n",
        "        lif_station_index (int): lift station index.\n",
        "        pump_index (int): pump index.                        \n",
        "\n",
        "    Returns:\n",
        "        Nothing\n",
        "    \"\"\"\n",
        "    query        = query_format.format(lif_station_index, pump_index)\n",
        "    outfilename  = filename_format.format(lif_station_index, pump_index)\n",
        "    print(query)\n",
        "    print(outfilename)    \n",
        "    if 1:\n",
        "        return\n",
        "    bla = ble[334]\n",
        "    #limit the chuncksize to avoid Memory Error\n",
        "    reader       = pd.read_sql(query, connection, chunksize=50000)\n",
        "\n",
        "    #read chuncks until the end\n",
        "    for chunk in reader:\n",
        "        temp_regs = chunk\n",
        "        #append\n",
        "        if os.path.isfile(outfilename):\n",
        "            temp_regs.to_csv(outfilename,encoding='utf-8', mode='a', header=False)\n",
        "        else:\n",
        "            temp_regs.to_csv(outfilename,encoding='utf-8')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMfyz47E8oXD",
        "colab_type": "text"
      },
      "source": [
        "**Alarm table processing**\n",
        "\n",
        "Alarm table is the biggest table with data from all the sewage lift stations\n",
        "\n",
        "This table has a pattern determined by the SCADA System environment. This means that the table structure  is created by the product and the records creation are determined by the application the user created. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjihzMXUIkTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#query format string to return alarms\n",
        "query_format = \"\"\"SELECT to_char(INTIME, 'yyyy-mm-dd HH24:MI:SS') as in_time,\n",
        "                         to_char(OUTTIME, 'yyyy-mm-dd HH24:MI:SS') as out_time,\n",
        "                         MESSAGE, TAG\n",
        "                  FROM SYSTEM.ALARMS\n",
        "                  WHERE AREA = 'area_{:0>2d}' \n",
        "                  ORDER BY INTIME\"\"\"\n",
        "\n",
        "#filename format string to save alarms\n",
        "filename_format = f'{DATASETS_DIR}alarms_area_'+'{:0>2d}.csv'\n",
        "\n",
        "#reading alarm table from \n",
        "for idx in range(NUMBER_OF_LIFT_STATIONS):\n",
        "    lift_station_idx = idx + 1\n",
        "\n",
        "    #call function to create csv file\n",
        "    create_csvfile_from_query(connection, \n",
        "                              query_format, \n",
        "                              filename_format, \n",
        "                              lift_station_idx,\n",
        "                              0)\n",
        "   \n",
        "    temp_outfilename  = filename_format.format(lift_station_idx)\n",
        "    final_outfilename = f'{DATASETS_DIR}alarms_area_{lift_station_idx:0>2d}w.csv'\n",
        "\n",
        "    #creates the final version removing some inconsistency (duplicates)\n",
        "    final_file = open(final_outfilename, 'w', encoding = \"utf-8\")\n",
        "    last_row    = None #last row\n",
        "    last_dh     = None #last dh\n",
        "    cur_values  = [] #list of values to remove duplicates\n",
        "    idxf = 0 #final file row count\n",
        "\n",
        "    #the remove duplicates operation could be done with pandas operation\n",
        "    #but this code avoid memory error\n",
        "\n",
        "    #read the temp file removing duplicates\n",
        "    with open(temp_outfilename, 'r', encoding = \"utf-8\") as temp_file:\n",
        "        for line in temp_file:\n",
        "            curdh   = line.split(',',2)[1] #datetime\n",
        "            curline = line.split(',',1)[1] #entire line\n",
        "            #check if timestamp has changed to initialize list of \n",
        "            #duplicated values\n",
        "            if curdh != last_dh:\n",
        "                cur_values = []\n",
        "\n",
        "            #check if it is a duplicate before creating line\n",
        "            if ((last_row == None) or (curline != last_row)) and \\\n",
        "                (curline not in cur_values):\n",
        "\n",
        "                #if first line, writes the header\n",
        "                if idxf == 0:\n",
        "                    final_file.write(',%s'%(curline))\n",
        "                else:\n",
        "                    final_file.write('%d,%s'%(idxf - 1,curline))            \n",
        "                idxf += 1\n",
        "                cur_values.append(curline)\n",
        "            last_row = curline\n",
        "            last_dh = curdh\n",
        "    \n",
        "    #close files\n",
        "    temp_file.close()\n",
        "    final_file.close()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bavSXWqzZC5D",
        "colab_type": "text"
      },
      "source": [
        "**History table related to power energy meter data (current, voltage and power)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlIALnJyIkTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#query format string to return records\n",
        "query_format = \"\"\"SELECT to_char(record_timestamp, \n",
        "                                 'yyyy-mm-dd HH24:MI:SS') as timestamp, \n",
        "                      current_A,current_B,current_C,\n",
        "                      voltage_RS,voltage_ST,voltage_RT,active_power,power_factor \n",
        "                FROM SYSTEM.INST_AREA_{0:0>2d}_MGE{1:0>2d}_{0}\"\"\"\n",
        "\n",
        "#filename format string to save records into csv\n",
        "filename_format = f'{DATASETS_DIR}pump_area_'+'{:0>2d}_{:0>2d}.csv'\n",
        "\n",
        "for idx1 in range(NUMBER_OF_LIFT_STATIONS):\n",
        "    lift_station_idx = idx1 + 1  \n",
        "    for idx2 in range(PUMPS_PER_LIFT_STATION[idx]):      \n",
        "        pump_idx = idx2 + 1\n",
        "        #call function to create csv file\n",
        "        create_csvfile_from_query(connection, \n",
        "                                  query_format, \n",
        "                                  filename_format, \n",
        "                                  lift_station_idx,\n",
        "                                  pump_idx)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OEORmRvbtiN",
        "colab_type": "text"
      },
      "source": [
        "**History table related to instruments data (eg.: level and pumps current)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amo1R4osIkTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#query format string to return records\n",
        "query_format = \"\"\"SELECT to_char(record_timestamp, \n",
        "                                'yyyy-mm-dd HH24:MI:SS') as timestamp, a.*\n",
        "               FROM SYSTEM.TAB_INST_AREA_{0:0>2d} a\"\"\"\n",
        "\n",
        "#filename format string to save records into csv\n",
        "filename_format = f'{DATASETS_DIR}tab_inst_area_'+'{:0>2d}.csv'\n",
        "\n",
        "#this history does not have pump\n",
        "pump_idx = 0\n",
        "\n",
        "for idx1 in range(NUMBER_OF_LIFT_STATIONS):\n",
        "    lift_station_idx = idx1 + 1  \n",
        "    #call function to create csv file\n",
        "    create_csvfile_from_query(connection, \n",
        "                              query_format, \n",
        "                              filename_format, \n",
        "                              lift_station_idx,\n",
        "                              pump_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_v8yRROdW_g",
        "colab_type": "text"
      },
      "source": [
        "**History table related to system events**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43JCzSgUIkTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#query format string to return records\n",
        "query_format = \"\"\"SELECT to_char(record_timestamp, \n",
        "                                 'yyyy-mm-dd HH24:MI:SS') as record_timestamp,\n",
        "                         to_char(eventtime, \n",
        "                                 'yyyy-mm-dd HH24:MI:SS') as eventtime, \n",
        "                         event_message, event_comment\n",
        "           from SYSTEM.SYS_EVENTS\"\"\"\n",
        "\n",
        "#filename format string to save records into csv\n",
        "filename_format = f'{DATASETS_DIR}tab_events.csv'\n",
        "\n",
        "#this history does not have lift station or pump index\n",
        "lift_station_idx = 0\n",
        "pump_idx = 0\n",
        "\n",
        "#call function to create csv file\n",
        "create_csvfile_from_query(connection, \n",
        "                          query_format, \n",
        "                          filename_format, \n",
        "                          lift_station_idx,\n",
        "                          pump_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPuKntOTgMEi",
        "colab_type": "text"
      },
      "source": [
        "**History table related to totalizations per day**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc8dhELdIkT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#query format string to return records\n",
        "query_format = \"\"\"select to_char(record_timestamp, \n",
        "                                'yyyy-mm-dd HH24:MI:SS') as record_timestamp, \n",
        "                         a.*\n",
        "               from SYSTEM.TAB_TOTPERDAY_AREA_{0:0>2d} a\"\"\"\n",
        "\n",
        "#filename format string to save records into csv\n",
        "filename_format = f'{DATASETS_DIR}tab_totperday_area_'+'{:0>2d}.csv'\n",
        "\n",
        "#this history does not have pump\n",
        "pump_idx = 0\n",
        "\n",
        "for idx1 in range(NUMBER_OF_LIFT_STATIONS):\n",
        "    lift_station_idx = idx1 + 1  \n",
        "    #call function to create csv file\n",
        "    create_csvfile_from_query(connection, \n",
        "                              query_format, \n",
        "                              filename_format, \n",
        "                              lift_station_idx,\n",
        "                              pump_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_dyyvMagYy4",
        "colab_type": "text"
      },
      "source": [
        "**History table related to the events written by the operators**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB_XlmueIkT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#query format string to return records\n",
        "query_format = \"\"\"select to_char(record_timestamp, \n",
        "                                 'yyyy-mm-dd HH24:MI:SS') as record_timestamp,\n",
        "                         to_char(eventtime, \n",
        "                                 'yyyy-mm-dd HH24:MI:SS') as eventtime, a.*\n",
        "           from SYSTEM.HIST_OPERATOR_EVENTS a\"\"\"\n",
        "\n",
        "#filename format string to save records into csv\n",
        "filename_format = f'{DATASETS_DIR}hist_operator_events.csv'\n",
        "\n",
        "#this history does not have lift station or pump index\n",
        "lift_station_idx = 0\n",
        "pump_idx = 0\n",
        "\n",
        "#call function to create csv file\n",
        "create_csvfile_from_query(connection, \n",
        "                          query_format, \n",
        "                          filename_format, \n",
        "                          lift_station_idx,\n",
        "                          pump_idx)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE6UmPSXIkUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1oetKDuRLX6g"
   },
   "source": [
    "**A jupyter notebook that demonstrates how to:**\n",
    "\n",
    "1. Connect to Oracle database;\n",
    "2. Run a query limiting sizes of results;\n",
    "3. Create a csv file with results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cx_Oracle\n",
      "  Downloading https://files.pythonhosted.org/packages/d5/15/d38862a4bd0e18d8ef2a3c98f39e743b8951ec5efd8bc63e75db04b9bc31/cx_Oracle-7.3.0-cp36-cp36m-manylinux1_x86_64.whl (737kB)\n",
      "\u001b[K    100% |████████████████████████████████| 737kB 316kB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: cx-Oracle\n",
      "Successfully installed cx-Oracle-7.3.0\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#installing cx_Oracle wich is not present at docker\n",
    "!pip install cx_Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vwxmAcrVIkTI"
   },
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "DPI-1047: Cannot locate a 64-bit Oracle Client library: \"libclntsh.so: cannot open shared object file: No such file or directory\". See https://oracle.github.io/odpi/doc/installation.html#linux for help",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-55da8c048ded>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                                \u001b[0mdsn_tns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                                \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"UTF-8\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                                nencoding = \"UTF-8\")\n\u001b[0m",
      "\u001b[0;31mDatabaseError\u001b[0m: DPI-1047: Cannot locate a 64-bit Oracle Client library: \"libclntsh.so: cannot open shared object file: No such file or directory\". See https://oracle.github.io/odpi/doc/installation.html#linux for help"
     ]
    }
   ],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "from IPython.display import display,clear_output\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import cx_Oracle\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "ip = 'database'\n",
    "port = 1521\n",
    "SID = 'ORCLCDB'\n",
    "user = 'sys'\n",
    "password = 'Oradoc_db1'\n",
    "\n",
    "dsn_tns = cx_Oracle.makedsn(ip, port, SID)\n",
    "\n",
    "connection = cx_Oracle.connect(user, \n",
    "                               password, \n",
    "                               dsn_tns, \n",
    "                               encoding = \"UTF-8\", \n",
    "                               nencoding = \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dk29uRf6IkTT"
   },
   "outputs": [],
   "source": [
    "mges_por_eee = [2,2,3,3,3,1,2,3,2,2,3,3,2,2,2,2,3,2,2,2,2,2,2,2,2,2,2,2,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AjihzMXUIkTa"
   },
   "outputs": [],
   "source": [
    "for idx in range(1,31):\n",
    "    query = \"\"\"select to_char(INTIME, 'yyyy-mm-dd HH24:MI:SS') as INTIME_,\n",
    "                      to_char(OUTTIME, 'yyyy-mm-dd HH24:MI:SS') as OUTTIME_,\n",
    "                      MESSAGE, TAG\n",
    "               FROM SYSTEM.ALARMS\n",
    "               WHERE AREA = 'UTR_%02d' \n",
    "               ORDER BY INTIME\"\"\"%(idx)\n",
    "\n",
    "    reader = pd.read_sql(query, connection, chunksize=50000)\n",
    "    i = 0\n",
    "    outfilename = r'csv_datasets/alarms_utr_%02d.csv' % (idx)\n",
    "    outfilenamew = r'csv_datasets/alarms_utr_%02dw.csv' % (idx)    \n",
    "    #df = pd.DataFrame()\n",
    "    for chunk in reader:\n",
    "      #query = \"\"\"select * from alarms_utr14 where to_char(INTIME_, 'yyyy') = '%d'\"\"\"%(idx)\n",
    "      #df = df.append(chunk)\n",
    "\n",
    "\n",
    "      temp_regs = chunk\n",
    "      if os.path.isfile(outfilename):\n",
    "        temp_regs.to_csv(outfilename,encoding='utf-8', mode='a', header=False)\n",
    "      else:\n",
    "        temp_regs.to_csv(outfilename,encoding='utf-8')\n",
    "    print(idx)\n",
    "\n",
    "    fw = open(outfilenamew, 'w', encoding = \"utf-8\")\n",
    "    last_row = None\n",
    "    last_dh = None\n",
    "    cur_values = []\n",
    "    idxf = 0\n",
    "\n",
    "    with open(outfilename, 'r', encoding = \"utf-8\") as fr:\n",
    "        for line in fr:\n",
    "            curdh = line.split(',',2)[1]\n",
    "            curline = line.split(',',1)[1]\n",
    "            if curdh != last_dh:\n",
    "                cur_values = []\n",
    "\n",
    "            if ((last_row == None) or (curline != last_row)) and (curline not in cur_values):\n",
    "                if idxf == 0:\n",
    "                    fw.write(',%s'%(curline))\n",
    "                else:\n",
    "                    fw.write('%d,%s'%(idxf - 1,curline))            \n",
    "                idxf += 1\n",
    "                cur_values.append(curline)\n",
    "            last_row = curline\n",
    "            last_dh = curdh\n",
    "    fr.close()\n",
    "    fw.close()\n",
    "\n",
    "        \n",
    "\n",
    "    #df = pd.read_csv(outfilename)\n",
    "\n",
    "    #df.sort_values('INTIME_')\n",
    "    #df.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "    #df.sort_values(by=['INTIME_'])\n",
    "    #df.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "    #df.to_csv(outfilename,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RlIALnJyIkTg"
   },
   "outputs": [],
   "source": [
    "for utr in range(1,31):\n",
    "    for mge in range(1,mges_por_eee[utr - 1] +1 ):\n",
    "        query = \"\"\"select to_char(e3timestamp, 'yyyy-mm-dd HH24:MI:SS') as timestamp, IA,IB,IC,URS,UST,URT,PA,FP \n",
    "                   from SYSTEM.INST_UTR_%02d_MGE%02d_%d\"\"\" % (utr, mge,utr)\n",
    "    \n",
    "        reader = pd.read_sql(query, connection, chunksize=50000)\n",
    "        i = 0\n",
    "        outfilename = r'csv_datasets/mge_utr_%02d_%d.csv' % (utr,mge)\n",
    "        for chunk in reader:\n",
    "            temp_regs = chunk\n",
    "            if os.path.isfile(outfilename):\n",
    "                temp_regs.to_csv(outfilename,encoding='utf-8', mode='a', header=False)\n",
    "            else:\n",
    "                temp_regs.to_csv(outfilename,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "amo1R4osIkTo"
   },
   "outputs": [],
   "source": [
    "for utr in range(1,31):\n",
    "    query = \"\"\"select to_char(e3timestamp, 'yyyy-mm-dd HH24:MI:SS') as timestamp, a.*\n",
    "               from SYSTEM.TAB_INST_UTR_%02d a\"\"\" % (utr)\n",
    "\n",
    "    reader = pd.read_sql(query, connection, chunksize=50000)\n",
    "    i = 0\n",
    "    outfilename = r'csv_datasets/tab_inst_utr_%02d.csv' % (utr)\n",
    "    for chunk in reader:\n",
    "        temp_regs = chunk\n",
    "        if os.path.isfile(outfilename):\n",
    "            temp_regs.to_csv(outfilename,encoding='utf-8', mode='a', header=False)\n",
    "        else:\n",
    "            temp_regs.to_csv(outfilename,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "43JCzSgUIkTu"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"select to_char(e3timestamp, 'yyyy-mm-dd HH24:MI:SS') as e3timestamp,\n",
    "                  to_char(eventtime, 'yyyy-mm-dd HH24:MI:SS') as eventtime, EVENTMESSAGE, EVENTCOMMENT\n",
    "           from SYSTEM.TAB_EVENTS\"\"\"\n",
    "\n",
    "reader = pd.read_sql(query, connection, chunksize=50000)\n",
    "i = 0\n",
    "outfilename = r'csv_datasets/tab_events.csv'\n",
    "for chunk in reader:\n",
    "    temp_regs = chunk\n",
    "    if os.path.isfile(outfilename):\n",
    "        temp_regs.to_csv(outfilename,encoding='utf-8', mode='a', header=False)\n",
    "    else:\n",
    "        temp_regs.to_csv(outfilename,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gc8dhELdIkT1"
   },
   "outputs": [],
   "source": [
    "for utr in range(1,31):\n",
    "    query = \"\"\"select to_char(e3timestamp, 'yyyy-mm-dd HH24:MI:SS') as timestamp, a.*\n",
    "               from SYSTEM.TAB_TOTDIA_UTR_%02d a\"\"\" % (utr)\n",
    "\n",
    "    reader = pd.read_sql(query, connection, chunksize=50000)\n",
    "    i = 0\n",
    "    outfilename = r'csv_datasets/tab_totdia_utr_%02d.csv' % (utr)\n",
    "    for chunk in reader:\n",
    "        temp_regs = chunk\n",
    "        if os.path.isfile(outfilename):\n",
    "            temp_regs.to_csv(outfilename,encoding='utf-8', mode='a', header=False)\n",
    "        else:\n",
    "            temp_regs.to_csv(outfilename,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dB_XlmueIkT6"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"select to_char(e3timestamp, 'yyyy-mm-dd HH24:MI:SS') as e3timestamp,\n",
    "                  to_char(evento, 'yyyy-mm-dd HH24:MI:SS') as eventtime, a.*\n",
    "           from SYSTEM.HIST_OCORRENCIAS a\"\"\"\n",
    "\n",
    "reader = pd.read_sql(query, connection, chunksize=50000)\n",
    "i = 0\n",
    "outfilename = r'csv_datasets/hist_ocorrencias.csv'\n",
    "for chunk in reader:\n",
    "    temp_regs = chunk\n",
    "    if os.path.isfile(outfilename):\n",
    "        temp_regs.to_csv(outfilename,encoding='utf-8', mode='a', header=False)\n",
    "    else:\n",
    "        temp_regs.to_csv(outfilename,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vE6UmPSXIkUA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "step_2-data-collection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

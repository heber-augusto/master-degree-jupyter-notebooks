{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "step_4-data-preparation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oetKDuRLX6g",
        "colab_type": "text"
      },
      "source": [
        "**This jupyter notebook demonstrates how to:**\n",
        "\n",
        "1. Create a multivariate timeseries using different datasets:\n",
        " - categorical data from lift stations;\n",
        " - Weather stations data;\n",
        " - Alarm events;\n",
        " - Instrument data (timeseries containing current from pumps and level);\n",
        " - eletric meters timeseries;\n",
        " - daily totalizers timeseries.\n",
        "\n",
        "2. Some data preparation:\n",
        " - creation of timeseries from events dataset;\n",
        " - cleaning instrument or aquisition errors;\n",
        " - convertion (eg.: str to float);\n",
        " - removal of deactivation periods from lift stations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKZSgJ_j8wog",
        "colab_type": "text"
      },
      "source": [
        "**Mount google drive to access files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OwMW61e8uNe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ec3412a6-7a75-4c1f-8d54-1b1b2e7446b3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk29uRf6IkTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Important defines:\n",
        "#total number of lift stations\n",
        "NUMBER_OF_LIFT_STATIONS = 30 \n",
        "\n",
        "#number of pumps per lift stations\n",
        "PUMPS_PER_LIFT_STATION  = [2,2,3,3,3,1,2,3,2,2,3,3,2,2,2,\n",
        "                           2,3,2,2,2,2,2,2,2,2,2,2,2,2,2]\n",
        "\n",
        "#google drive folder where datasets are stored\n",
        "DATASETS_DIR = r'/content/gdrive/My Drive/datasets/'                         \n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwxmAcrVIkTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2VfWFlomo9U",
        "colab_type": "text"
      },
      "source": [
        "**Load lift stations register**\n",
        "\n",
        "This data frame contains characteristics and specifications about sewage lift stations\n",
        "\n",
        "Some columns (listed above) contains float values with comma instead of dot. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HeJZGWRYy0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lift_station_register = pd.read_csv(DATASETS_DIR + r'sewage_pumping_stations_base.csv')\n",
        "\n",
        "#list of columns to transform into float, changing comma for dot\n",
        "columns_to_change_to_float = ['utmx', 'utmy', 'nivel_max','vazao_recalque', \n",
        "                              'altura_manometrica','extensao_recalque',\n",
        "                              'potencia_instalada']\n",
        "\n",
        "for column in columns_to_change_to_float:\n",
        "  try:\n",
        "    lift_station_register[column] = lift_station_register[column].str.replace(',', '.').astype(float)\n",
        "  except:\n",
        "    print(f'Erro changing type of column: {column}')\n",
        "    continue\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4_eakRL3edy",
        "colab_type": "text"
      },
      "source": [
        "**Weather stations data**\n",
        "\n",
        "Files where downloaded from http://www.inmet.gov.br/portal/index.php?r=bdmep/bdmep\n",
        "\n",
        "Weather data are related to Sewage Lift Stations events because because part of the rainwater is improperly connected to the sewer network.\n",
        "\n",
        "This dataset is composed by data from 9 weather stations wich are located in Belo Horizonte region. They are near sewage lift stations analysed at this master degree work.\n",
        "\n",
        "Each weather station file contains daily precipitation between January 1, 2010 and December 31, 2018.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZChqWCzNvr5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load weather stations register containing ids from all weather stations\n",
        "weather_stations = pd.read_csv(DATASETS_DIR + r'cadastro_estacoes.csv')\n",
        "\n",
        "#load 9 weather stations datasets\n",
        "weather_stations_data_list = []\n",
        "for i,row in weather_stations.iterrows():\n",
        "    #load the dataset from each weather station \n",
        "    #files names uses the id from each weather station\n",
        "    weather_station_data = pd.read_csv(DATASETS_DIR + r'estacao_{0}.csv'.format(row['id']),delimiter=';')\n",
        "    #set the datetime index\n",
        "    weather_station_data['datahora'] = pd.to_datetime(weather_station_data['Data'],format='%d/%m/%Y')\n",
        "    weather_station_data.index = pd.to_datetime(weather_station_data['datahora'])\n",
        "    #change the precipitation column name preparing for concatenation\n",
        "    new_column_name = f\"WeatherStation_{row['id']}\"\n",
        "    weather_station_data = weather_station_data.rename(columns = {'Precipitacao':new_column_name})\n",
        "    #append each weather station dataset to a list for letter concatenation\n",
        "    weather_stations_data_list.append(weather_station_data[['datahora',new_column_name]])\n",
        "\n",
        "#contatenate weather station datasets    \n",
        "weather_stations_datas = pd.concat(weather_stations_data_list, axis=1)\n",
        "weather_stations_datas = weather_stations_datas.drop(columns=['datahora',])\n",
        "#fill values na with 0\n",
        "weather_stations_datas = weather_stations_datas.fillna(0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N_00gzoKSoN",
        "colab_type": "text"
      },
      "source": [
        "**Intervals with operation interruption from some lift stations**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HOi4C0NKtPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#some sewage lift station were deactivated after a specific date \n",
        "#the dict below helps to get correct operation interval\n",
        "lifting_operation_intervals = {}\n",
        "lifting_operation_intervals[3] = {'ini':pd.to_datetime(datetime.date(2011,1,1)) ,\n",
        "                            'fim':pd.to_datetime(datetime.date(2013,4,8))}\n",
        "lifting_operation_intervals[4] = {'ini':pd.to_datetime(datetime.date(2011,1,1)) ,\n",
        "                            'fim':pd.to_datetime(datetime.date(2013,3,21))}\n",
        "lifting_operation_intervals[5] = {'ini':pd.to_datetime(datetime.date(2011,1,1)) ,\n",
        "                            'fim':pd.to_datetime(datetime.date(2013,3,28))}\n",
        "lifting_operation_intervals[6] = {'ini':pd.to_datetime(datetime.date(2011,1,1)) ,\n",
        "                            'fim':pd.to_datetime(datetime.date(2012,7,4))}\n",
        "lifting_operation_intervals[7] = {'ini':pd.to_datetime(datetime.date(2011,1,1)) ,\n",
        "                            'fim':pd.to_datetime(datetime.date(2016,11,8))}\n",
        "lifting_operation_intervals[18] = {'ini':pd.to_datetime(datetime.date(2011,1,1)) ,\n",
        "                             'fim':pd.to_datetime(datetime.date(2017,8,30))}\n",
        "lifting_operation_intervals[24] = {'ini':pd.to_datetime(datetime.date(2011,1,1)) ,\n",
        "                             'fim':pd.to_datetime(datetime.date(2016,11,27))}\n",
        "lifting_operation_intervals[26] = {'ini':pd.to_datetime(datetime.date(2011,1,1)) ,\n",
        "                             'fim':pd.to_datetime(datetime.date(2017,6,17))}\n",
        "lifting_operation_intervals[27] = {'ini':pd.to_datetime(datetime.date(2011,1,1)) ,\n",
        "                             'fim':pd.to_datetime(datetime.date(2016,12,8))}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23ARz-orYu4l",
        "colab_type": "text"
      },
      "source": [
        "**The function bellow helps to access alarm events with a generic content**\n",
        "\n",
        "The function returns alarm and event data removing specific tags related to sewage lift stations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdbDFeJi6_bS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_alarm_data(lift_station_index):\n",
        "    \"\"\"Function to return alarm data.\n",
        "\n",
        "    Get alarms and events from dataset changing names and messages to \n",
        "    standardize the dataframe result.\n",
        "\n",
        "    This function needs two global variables already declared: \n",
        "        lift_station_register: a dataframe containing information and \n",
        "          specifications from lift stations\n",
        "        lifting_operation_intervals: a dictionary containing operating intervals \n",
        "          for sewage pumping stations\n",
        "\n",
        "    Args:\n",
        "        lift_station_index (int): index from the sewage lift station.\n",
        "\n",
        "    Returns:\n",
        "        dataframe: alarms dataframe with\n",
        "\n",
        "    \"\"\"\n",
        "    #read alarm files\n",
        "    alarms_file = DATASETS_DIR + r'alarms_utr_{:>02}w.csv'.format(lift_station_index)\n",
        "\n",
        "    #verify if lift station has a operation interval to use just data \n",
        "    #during its operation period.\n",
        "    try:\n",
        "        start = lifting_operation_intervals[lift_station_index]['ini']\n",
        "        end   = lifting_operation_intervals[lift_station_index]['fim']\n",
        "        print(f'{lift_station_register.iloc[lift_station_index - 1].nome}:{ini} a {fim}')\n",
        "    except:\n",
        "        start = pd.to_datetime(datetime.date(2011,1,1))\n",
        "        end   = pd.to_datetime(datetime.date(2018,7,31))\n",
        "        pass    \n",
        "    \n",
        "    alarms = None\n",
        "    first = True\n",
        "    #read file with chunks to avoid Memory error\n",
        "    reader = pd.read_csv(alarms_file, chunksize=50000)\n",
        "    for chunk in reader:\n",
        "        temp_regs = chunk\n",
        "        temp_regs['INTIME_']  = pd.to_datetime(temp_regs['INTIME_'])\n",
        "        temp_regs['OUTTIME_'] = pd.to_datetime(temp_regs['OUTTIME_'])    \n",
        "\n",
        "        #create the dataframe at the first chunk and append later \n",
        "        if first:\n",
        "            alarms = temp_regs\n",
        "            first = False\n",
        "        else:\n",
        "            alarms = alarms.append(temp_regs)\n",
        "\n",
        "    #filter data between end and start dates\n",
        "    alarms = alarms[(alarms.INTIME_ >= start) & (alarms.INTIME_ <= end)] \n",
        "    #create index for datetime\n",
        "    alarms.index = pd.to_datetime(alarms['INTIME_'])\n",
        "\n",
        "    #set tag name for sewage level signal\n",
        "    tag_level      = f'LI01-{lift_station_index}'\n",
        "\n",
        "    #replaces tags and values ​​by generic content to facilitate\n",
        "    #treatment of data\n",
        "    for pump_index in range(1,4):\n",
        "        tag_pump          = 'B{:>02}-{}'.format(pump_index,lift_station_index)\n",
        "        new_tag_pump      = f'pump{pump_index}'\n",
        "        tag_lift_station  = 'UTR_{:>02}'.format(lift_station_index)\n",
        "        tag_eletric       = 'MGE{:>02}-{}'.format(pump_index,lift_station_index)\n",
        "        new_tag_eletric   = f'eletrica_bomba{pump_index}'\n",
        "\n",
        "        #change alarms messages with generic contents\n",
        "        alarms.loc[alarms.TAG == tag_pump,    'TAG']  = new_tag_pump\n",
        "        alarms.loc[alarms.TAG == tag_lift_station,      'TAG']  = 'lift_station'\n",
        "        alarms.loc[alarms.TAG == tag_level,    'TAG']  = 'level'\n",
        "        alarms.loc[alarms.TAG == tag_eletric, 'TAG']  = new_tag_eletric\n",
        "\n",
        "        for fase in ['R', 'S', 'T', 'RS', 'RT', 'ST']:\n",
        "          messages = ['Corrente Baixa fase {} - Normalizado'.format(fase),\n",
        "                      'Corrente Baixa fase {}'.format(fase),\n",
        "                      'Corrente Alta fase {} - Normalizado'.format(fase),\n",
        "                      'Corrente Alta fase {}'.format(fase),\n",
        "                      'Tensão {} Alta - Normalizado'.format(fase),\n",
        "                      'Tensão {} Alta'.format(fase),\n",
        "                      'Tensão {} Baixa - Normalizado'.format(fase),\n",
        "                      'Tensão {} Baixa'.format(fase),]\n",
        "          for message in messages:\n",
        "            new_message = message.replace(' {}'.format(fase),'')\n",
        "            alarms.loc[alarms.MESSAGE == message, 'MESSAGE']  = new_message\n",
        "\n",
        "\n",
        "    return alarms"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8GTkBzWpJxt",
        "colab_type": "text"
      },
      "source": [
        "**The function bellow helps to access instruments data with a generic content**\n",
        "\n",
        "The function returns instrument data (current for pump, level and timestamp) removing specific tags related to sewage lift stations. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iYrKuzqpeq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_instrument_data(lift_station_index):\n",
        "    \"\"\"Function to return instrument data.\n",
        "\n",
        "    Get alarms and events from dataset changing names and messages to \n",
        "    standardize the dataframe result.\n",
        "\n",
        "    This function needs two global variables already declared: \n",
        "        lift_station_register: a dataframe containing information and \n",
        "          specifications from lift stations\n",
        "        lifting_operation_intervals: a dictionary containing operating intervals \n",
        "          for sewage pumping stations\n",
        "\n",
        "    Args:\n",
        "        lift_station_index (int): index from the sewage lift station.\n",
        "\n",
        "    Returns:\n",
        "        dataframe: instrument dataframe level and pump current values\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #verify if lift station has a operation interval to use just data \n",
        "    #during its operation period.\n",
        "    try:\n",
        "        start = lifting_operation_intervals[lift_station_index]['ini']\n",
        "        end   = lifting_operation_intervals[lift_station_index]['fim']\n",
        "        print(f'{lift_station_register.iloc[lift_station_index - 1].nome}:{ini} a {fim}')\n",
        "    except:\n",
        "        start = pd.to_datetime(datetime.date(2011,1,1))\n",
        "        end   = pd.to_datetime(datetime.date(2018,7,31))\n",
        "        pass\n",
        "\n",
        "    #read dataframe from file \n",
        "    data_file   = DATASETS_DIR + r'tab_inst_utr_{:>02}.csv'.format(lift_station_index)  \n",
        "    instrument_data   = pd.read_csv(data_file)  \n",
        "    instrument_data['TIMESTAMP'] = pd.to_datetime(instrument_data['TIMESTAMP'])\n",
        "    instrument_data = instrument_data.sort_values(by=['TIMESTAMP'])\n",
        "    instrument_data = instrument_data[(instrument_data.TIMESTAMP >= start) & \n",
        "                                      (instrument_data.TIMESTAMP <= end)]\n",
        "    instrument_data.index = pd.to_datetime(instrument_data['TIMESTAMP'])\n",
        "\n",
        "    #rename level column name\n",
        "    column_level_name = 'LI01_{}'.format(lift_station_index)\n",
        "    instrument_data = instrument_data.rename(columns={column_level_name: 'level',})\n",
        "\n",
        "\n",
        "    #get limits for level signal\n",
        "    limits = {'max':3*lift_station_register.iloc[lift_station_index - 1]['nivel_max'],\n",
        "              'min':0.0}    \n",
        "    \n",
        "    #cleaning level value errors\n",
        "    #if less than 0, starts with 0\n",
        "    instrument_data.loc[instrument_data.level < 0, 'level'] = 0.0\n",
        "    \n",
        "    #set invalid level value at a column\n",
        "    instrument_data['level_inv_max'] = 0\n",
        "    instrument_data.loc[instrument_data.level > limits['max'], 'level_inv_max'] = 1\n",
        "    \n",
        "    #change column names with generic content \n",
        "    for pump_index in range(1,4):\n",
        "        tag_current = 'IB%02d_%d' % (pump_index,lift_station_index) \n",
        "        new_tag_current     = f'current{pump_index}'\n",
        "        new_tag_current_lim = f'corrente{pump_index}'\n",
        "        new_tag_pump        = f'bomba{pump_index}'\n",
        "\n",
        "        #if the pump does not exists, set current signal with 0\n",
        "        if tag_current in instrument_data.columns:\n",
        "          instrument_data = instrument_data.rename(columns={tag_current: new_tag_current,})\n",
        "        else:\n",
        "          instrument_data[new_tag_current] = 0.0\n",
        "\n",
        "        #get limits for current signal  \n",
        "        limits = {'max':3*lift_station_register.iloc[lift_station_index - 1][f'{new_tag_current_lim}_max'],\n",
        "                   'min':0}\n",
        "        \n",
        "        #initialize current value with 0 \n",
        "        if lift_station_register.iloc[lift_station_index - 1][new_tag_pump] == 0:\n",
        "          instrument_data[new_tag_current] = 0.0          \n",
        "        else:\n",
        "          #if less than 0, starts with 0\n",
        "          instrument_data.loc[instrument_data[new_tag_current] < limits['min'], \n",
        "                              new_tag_current] = 0.0          \n",
        "          \n",
        "        #set invalid level value at a column\n",
        "        column_inv_max_current = f'{new_tag_current_lim}_inv_max'\n",
        "        instrument_data[column_inv_max_current] = 0\n",
        "        instrument_data.loc[instrument_data[new_tag_current] > limits['max'], \n",
        "                            column_inv_max_current] = 1          \n",
        "    \n",
        "    #filter columns to be returned and adjust timestamp at 5 minute intervals\n",
        "    data_columns = ['level','level_inv_max', 'current1','current2','current3', \n",
        "                    'corrente1_inv_max','corrente2_inv_max','corrente3_inv_max']\n",
        "\n",
        "    #resample with 5 minutes interval\n",
        "    instrument_data = instrument_data.resample('5T').first()[data_columns]\n",
        "    instrument_data['TIMESTAMP'] = instrument_data.index\n",
        "    instrument_data['TIMESTAMP_fim'] = instrument_data['TIMESTAMP'] + np.timedelta64(300, 's')\n",
        "    instrument_data['DATA'] = instrument_data.index.date\n",
        "\n",
        "    return instrument_data\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EibtFXITp68x",
        "colab_type": "text"
      },
      "source": [
        "**The function bellow returns sewage lift station datasets**\n",
        "\n",
        "The function returns alarm, instrument, energy meter and totalizations data related to sewage lift stations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypzCNcCEhqt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_datasets(lift_station_index):\n",
        "    \"\"\"Return alarm, instrument, energy meter and totalizations data.\n",
        "\n",
        "    Args:\n",
        "        lift_station_index (int): index from the sewage lift station.\n",
        "\n",
        "    Returns:\n",
        "        dataframe: alarms dataframe\n",
        "        dataframe: instrument data dataframe (level and pump currents)\n",
        "        list: eletric meters dataframes\n",
        "        dataframe: totalizers data\n",
        "\n",
        "    \"\"\"\n",
        "    #get alarms dataframe\n",
        "    alarms = get_alarm_data(lift_station_index)\n",
        "\n",
        "    #get instrument dataframe\n",
        "    instrument_data = get_instrument_data(lift_station_index)\n",
        "\n",
        "    #get eletric meter files and dataframe\n",
        "    number_of_pumps = PUMPS_PER_LIFT_STATION[lift_station_index - 1]\n",
        "    eletric_meter_files   = [DATASETS_DIR + r'mge_utr_{:>02}_{}.csv'.format(\n",
        "        lift_station_index, \n",
        "        pump_index) for pump_index in range(1, number_of_pumps + 1)]\n",
        "    eletric_meters    = [pd.read_csv(meter_file) for meter_file in eletric_meter_files]\n",
        "\n",
        "    #totalizers by day dataframe\n",
        "    totday_file = DATASETS_DIR + r'tab_totdia_utr_{:>02}.csv'.format(lift_station_index)\n",
        "    totday  =  pd.read_csv(totday_file)  \n",
        "    totday['TIMESTAMP'] = pd.to_datetime(totday['TIMESTAMP'])\n",
        "    totday = totday.sort_values(by=['TIMESTAMP'])\n",
        "    \n",
        "    return alarms, instrument_data, eletric_meters, totday"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4eFzTAUt0zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def end_of_overflow_test(row, column_name, limits):\n",
        "    \"\"\"test for the end of sewage overflow event\n",
        "\n",
        "    Args:\n",
        "        row: dataframe row containg values.\n",
        "        column_name: name of the column to.\n",
        "        limits: gives min and max limits for level\n",
        "\n",
        "    Returns:\n",
        "        bool: result of the test (True: the event ended)\n",
        "\n",
        "    \"\"\"\n",
        "    # set the end of the overflow event if a nan value is found or \n",
        "    # if the level value is half the max limit\n",
        "    if np.isnan(row[column_name]) | (row[column_name] < limits['max']/2):\n",
        "      return True\n",
        "    return False\n",
        "  \n",
        "def end_pump_activate_test(row, column_name, limits):\n",
        "    \"\"\"test for the end of pump activation\n",
        "\n",
        "    Args:\n",
        "        row: dataframe row containg values.\n",
        "        column_name: name of the column to.\n",
        "        limits: gives min and max limits for level\n",
        "\n",
        "    Returns:\n",
        "        bool: result of the test (True: the event ended)\n",
        "\n",
        "    \"\"\"\n",
        "    # set the end of the pump activation if a nan value is found or \n",
        "    # if the pump current is zero    \n",
        "    if np.isnan(row[column_name]) | (row[column_name] == 0):\n",
        "      return True\n",
        "    return False  \n",
        "\n",
        "\n",
        "def end_maintenance_test(row, column_name, limits):\n",
        "    \"\"\"test for the end of maintenance\n",
        "\n",
        "    Args:\n",
        "        row: dataframe row containg values.\n",
        "        column_name: name of the column to.\n",
        "        limits: gives min and max limits for level\n",
        "\n",
        "    Returns:\n",
        "        bool: result of the test (True: the event ended)\n",
        "\n",
        "    \"\"\"\n",
        "    # set the end of the maintenance event if a nan value is found or \n",
        "    # if the pump current is more than zero      \n",
        "    if np.isnan(row[column_name]) | (row[column_name] > 0):\n",
        "      return True\n",
        "    return False\n",
        "  "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6pztskw8JBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_timeseries_from_events(\n",
        "    events, \n",
        "    multivar, \n",
        "    label, \n",
        "    func_test, \n",
        "    column_name, \n",
        "    limits):\n",
        "    \"\"\"create timeseries from events adding aditional information into the\n",
        "    multivariate timeseries\n",
        "\n",
        "    Args:\n",
        "        events: events dataframe which will be used to create timeseries\n",
        "        multivar: original multivariate timeseries\n",
        "        label: label from the event that will be used to create timeseries\n",
        "        func_test: a function that will be user to check the end of the event\n",
        "        column_name: name of the column that will be used with the func_test\n",
        "\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    label_contagem  = f'{label}_contagem'\n",
        "    label_duracao   = f'{label}_duracao'\n",
        "    label_ocorreu   = f'{label}_ocorreu'\n",
        "    label_ocorrendo = f'{label}_ocorrendo'    \n",
        "    multivar[label_contagem] = 0.0\n",
        "    multivar[label_duracao]  = 0.0\n",
        "    multivar[label_ocorreu]  = 0   \n",
        "    multivar[label_ocorrendo]  = 0\n",
        "    \n",
        "    # scans entire dataframe filling counters and events duration\n",
        "    row_iterator = events.iterrows()\n",
        "\n",
        "    for i, row in row_iterator:\n",
        "        # returns time series that are related to the event period\n",
        "        multivar_regs = multivar[((multivar.TIMESTAMP_fim > row['INTIME_']) & \n",
        "                                  (multivar.TIMESTAMP <= row['INTIME_'])) |\n",
        "                                 ((multivar.TIMESTAMP_fim > row['OUTTIME_']) & \n",
        "                                  (multivar.TIMESTAMP <= row['OUTTIME_'])) |\n",
        "                                 ((multivar.TIMESTAMP <= row['OUTTIME_']) & \n",
        "                                  (multivar.TIMESTAMP >= row['INTIME_']))\n",
        "                                ]\n",
        "        # scans records adding count and duration associated with the event\n",
        "        for index, row_var in multivar_regs.iterrows():\n",
        "          # check for the event end\n",
        "          if func_test(row_var, column_name, limits):\n",
        "            continue\n",
        "          \n",
        "          inicio = row_var['TIMESTAMP'] \n",
        "          fim    = row_var['TIMESTAMP_fim']\n",
        "          if inicio < row['INTIME_']:\n",
        "            inicio = row['INTIME_']\n",
        "          if fim > row['OUTTIME_']:\n",
        "            fim = row['OUTTIME_']\n",
        "          multivar.at[index, label_contagem]  = row_var[label_contagem] + 1\n",
        "          multivar.at[index, label_ocorrendo] = 1          \n",
        "          multivar.at[index, label_duracao] = row_var[label_duracao] + (fim - inicio)/np.timedelta64(1,'s')\n",
        "          # marks the occurrence of event only at the first index \n",
        "          # of the returned records \n",
        "          if index == 0:\n",
        "            multivar.at[index, label_ocorreu] = 1\n",
        "    \n",
        "    # calculate cumulative sum for event duration and count\n",
        "    multivar[f'{label_contagem}_cum'] = multivar[label_contagem].cumsum(axis = 0)\n",
        "    multivar[f'{label_duracao}_cum'] = multivar[label_duracao].cumsum(axis = 0)    \n",
        "    multivar[f'{label_ocorreu}_cum'] = multivar[label_ocorreu].cumsum(axis = 0)    \n",
        "    multivar[f'{label_ocorrendo}_cum'] = multivar[label_ocorrendo].cumsum(axis = 0)  \n",
        "    "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifmIn9P28M9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_and_clean(lift_station, debug = False):\n",
        "    \"\"\"get all datasets and call additional functions to make some \n",
        "    data preparation and transformation\n",
        "\n",
        "    Args:\n",
        "        lift_station: lift station index\n",
        "        debug: enable printing debug information\n",
        "\n",
        "\n",
        "    Returns:\n",
        "        multivariate dataframe containg all needed information\n",
        "\n",
        "    \"\"\"  \n",
        "    # get datasets that will be used\n",
        "    alarms, multivar, mges, totdia = get_datasets(lift_station)\n",
        "    # if debug, print deactivation intervals\n",
        "    if debug:\n",
        "        invalid_dates = set(multivar[(multivar.level_inv_max == 1) | \n",
        "                                     (multivar.corrente1_inv_max == 1) | \n",
        "                                     (multivar.corrente2_inv_max == 1) | \n",
        "                                     (multivar.corrente3_inv_max == 1) ].index.date)\n",
        "        # print information about intervals containing invalid instrument data \n",
        "        if len(invalid_dates) > 0:\n",
        "            print(f'lift_station {lift_station} :{len(invalid_dates)}    ' + \\\n",
        "                  f'---   {len(set(multivar[(multivar.corrente1_inv_max == 1)].index.date))}    ' + \\\n",
        "                  f'---   {len(set(multivar[(multivar.corrente2_inv_max == 1)].index.date))}    ' + \\\n",
        "                  f'---   {len(set(multivar[(multivar.corrente3_inv_max == 1)].index.date))}')\n",
        "  \n",
        "    # query for sewage overflow events\n",
        "    if debug:\n",
        "        print(f'{datetime.datetime.now()} - Lift station {lift_station}: processing sewage overflow events')  \n",
        "    mask = (alarms['MESSAGE'] == 'Limite Alto - Normalizado') & \\\n",
        "           (alarms['INTIME_'] <= alarms['OUTTIME_'])\n",
        "    overflow_events = alarms.loc[mask][['INTIME_','OUTTIME_']]\n",
        "  \n",
        "    # use level transmitter limits\n",
        "    limits = {'max':lift_station_register.iloc[elevatoria - 1]['nivel_max'],\n",
        "              'min':0.0}  \n",
        "    \n",
        "    # process overflow events\n",
        "    create_timeseries_from_events(\n",
        "        overflow_events, \n",
        "        multivar, \n",
        "        'extravasao', \n",
        "        end_of_overflow_test, \n",
        "        'level', \n",
        "        limits)\n",
        "    \n",
        "    # iterate over pumps creating time series for pump events \n",
        "    # (activation and maintenance)\n",
        "    for mge in range(1,4):\n",
        "        novo_tag_bomba    = f'bomba{mge}'\n",
        "        tag_corrente      = f'current{mge}'\n",
        "        max_current_tag   = f'corrente{mge}_max'\n",
        "    \n",
        "        # obtain pump current limits\n",
        "        limits = {'max':lift_station_register.iloc[lift_station - 1][max_current_tag],\n",
        "                  'min':0.0}\n",
        "    \n",
        "        if debug:    \n",
        "            print(f'{datetime.datetime.now()} - Lift station {lift_station}: processing pump activation {novo_tag_bomba}')\n",
        "        \n",
        "        #  query for pump activation events\n",
        "        mask = (alarms['MESSAGE'] == 'Bomba Desligou') & \\\n",
        "               (alarms['INTIME_'] <= alarms['OUTTIME_']) & \\\n",
        "               (alarms.TAG == novo_tag_bomba)\n",
        "        events = alarms.loc[mask][['INTIME_','OUTTIME_']]\n",
        "\n",
        "        # process pump activation events\n",
        "        create_timeseries_from_events(\n",
        "            events, \n",
        "            multivar, \n",
        "            f'acc_bomba{mge}', \n",
        "            end_pump_activate_test, \n",
        "            tag_corrente, \n",
        "            limits)\n",
        "        \n",
        "        if debug:\n",
        "            print(f'{datetime.datetime.now()} - Lift station {lift_station}: processing pump maintenance {novo_tag_bomba}')\n",
        "\n",
        "        #  query for maintenance events            \n",
        "        mask = (alarms['MESSAGE'] == 'Bomba saiu de Manutenção') & \\\n",
        "               (alarms['INTIME_'] <= alarms['OUTTIME_']) & \\\n",
        "               (alarms.TAG == novo_tag_bomba)\n",
        "        events = alarms.loc[mask][['INTIME_','OUTTIME_']]\n",
        "        \n",
        "        # process pump maintenance events\n",
        "        create_timeseries_from_events(\n",
        "            events, \n",
        "            multivar, \n",
        "            f'mnt_bomba{mge}', \n",
        "            end_maintenance_test, \n",
        "            tag_corrente, \n",
        "            limits)\n",
        " \n",
        "    return multivar\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd0iL2j58thC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#varre todas as elevatorias gerando arquivos com time series compiladas e com as devidas limpezas \n",
        "for lift_station in range(1,31):\n",
        "    multivar = get_data_and_clean(lift_station, True)\n",
        "    timeseries_file = DATASETS_DIR + f'timeseries_lift_station_{lift_station}_.csv'\n",
        "    multivar.to_csv(timeseries_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3X6phZ78wnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}